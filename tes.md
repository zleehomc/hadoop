# hadoop学习目的
## 传统大量计算问题
- 传统计算受限于处理器(用复杂的计算解决小量的数据)
- 解决方案就是许多电脑
#### 分布式操作系统
- 最好的解决方案
- 用多个电脑解决一个问题

#### 分布式系统的问题
- 编码麻烦
- 带宽受限
- 局部错误影响整体

#### 分布式操作系统的瓶颈
- 传统情况,数据只存在在一个中心
- 数据只有在用时候才进行传输
- 大量数据的传输受限(tb+每天,pb+总共的数据量)
---

## hadoop
#### 介绍
- 一种新的分布式计算方法
- 创始于google
- apache开源

#### hadoop核心概念
- 用高级语言写应用
- 节点的访问越少越好
- 数据提前进行分布
- 数据有备份所以可以更加可靠和高效
- hadoop是可扩展的和容错率高的

#### 可扩展性
- 添加节点可以线性的的提高容量(老师笔记:事实上并不能线性提高)
- 提高数据加载的能力

#### 容错情况
- 节点错误是不可避免的
- 一旦发生错误
> 1. 系统基础功能不会受到影响
> 2. 主机可以重新您分配不同的节点
> 3. 数据的复制已保证不会丢失数据
> 4. 节点恢复后可以重新自动加入集群

### hadoop常见的不同类型的分析
- 文本挖矿
- 主页建造
- 图像制作和分析
- 模式识别
- 协同过滤
- 模型预测
- 情绪分析
- 风险评估

### hadoop需要面临的问题

- 自然数据
1. 量
2. 速
3. 类
4. 真(4v,文档中未提及)
- 自然分析
1. 批处理
2. 并行
3. 数据分布

### hadoop分析的有点
- 以前不可能或者不切实际的分析
- 低消耗
- 时间少
- 高灵活性
- 近乎线性的扩展性(近乎----老师笔记中提到实际不可能线性)
- 问更大的问题(?)

### 总结
- 传统的大规模的计算用于解决销量数据
- 指数型的增长发展的分布式计算
- 分布式计算是很难得!!
- hadoop的挑战
1. 大量的数据
2. 容错率
3. 扩展性
4. 专注于数据

## hadoop基础概念和hdfs

![](http://i2.muimg.com/567571/1ffbbde91105ffed.png)
- Sqoop:连接db2和hadoop的桥梁
- Mahout:机器学习算法应用于hadoop
- Hive:将sql转换为MapReduce作业
- Pig:执行MapReduce的环境
- HBase:一个超级可扩展的键值存储
- Fluem:一个实时的加载程序，用来将数据流式传输到 Hadoop 中
- Oozie:管理 Hadoop 工作流

### hadoop核心组件:HDFS,MapReduce
- hdfs:存储数据的集群
- mapreduce:处理数据在集群上

#### 一个简单的hadoop集群
- 一个hadoop集群:一组一起运行的机器去存储数据和处理数据
- 一些节点:hdfs:存储数据的集群,mapreduce:处理数据在集群上
- 两个主节点:Namenode:管理hdfs,job tracker:管理Mapreduce

## hsfs基础概念
- hdfs是一个用java写的文件系统,基于google的gfs
- 基于本体的文件系统:ext3,ext4,xfs(前两者性能更好)
- 提供充足的存储
- hdfs对大数据处理能力很强
- 一次书写(不能修改,只能重新传)
- hdfs对大数据进行优化,流式读写(非随机)

### 文件是如何存储的?
- 数据时分散到块里的,会被分布当运行时候
- 每个块会被复制到不同的数据节点上(默认3个)
- namenode:存储元数据,包括6种读写指令

### namenode
- namenode后台进行必须实时运行
- 高效模式:两个namenode,active和standy,一个活跃,一个用来备份保持同步
- 传统模式:一个namenode,还有一个secoondarynamenode用来当读写达到一定量进行和磁盘的同步


## MapReduce

#### 什么是mapreduce?
- mapreduce是给节点分配任务的方法

#### mapreduce特点
- 自动分配和并行
- 容错
- 对于程序员来说很清晰这个概念(1.用java写 2.)
- 开发者可以专注于map和reduce的功能

#### 开发mapreduce的阶段
- mapper:
1. 每个map任务操作都在一个hdfs块上
2. map任务运行在存储该块的节点上
- 规划分类:
1. 从mapper手里对数据排序和分类
2. 承接map的完成和reduce的开始
- reducer:
1. 对整理好的数据进行操作
2. 产品输出


问题:04-34页html的键值对是如何reduce()出结果的?
